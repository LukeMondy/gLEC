{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an unstructured mesh\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> In this example, we use the ESRI Grid for Australia available from Geoscience Australia product catalogue (https://ecat.ga.gov.au/geonetwork/). You could download it when searching for Australian Bathymetry and Topography Grid, June 2009.  \n",
    "\n",
    "We also provide in data folder a low resolution GeoTIFF that can also be used for this tutorial (AUS_LR.tiff). \n",
    "\n",
    "We will first _reproject the dataset_ in UTM coordinates, then we will use _shapefiles and countours_ to clipped on region of interested and then we will use\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "## Notebook contents\n",
    "\n",
    "   - [Converting from lon/lat to metres](#Converting-from-lon/lat-to-metres)\n",
    "   - [Clipped elevation grid](#Clipped-elevation-grid)\n",
    "   - [X & Y axes](#X-&-Y-axes)\n",
    "   - [Define contour lines](#Define-contour-lines)\n",
    "   - [Unstructured elevation grid](#Unstructured-elevation-grid)\n",
    "   - [Visualisation](#Visualisation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "import numpy as np\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "import jigsawpy\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "label_size = 8\n",
    "matplotlib.rcParams['xtick.labelsize'] = label_size \n",
    "matplotlib.rcParams['ytick.labelsize'] = label_size\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting from lon/lat to metres\n",
    "\n",
    "To reproject the grid from lon/lat coordinates to UTM (metres), two main libraries are available within the Docker image:\n",
    "\n",
    "+ `pygeotools` -- https://github.com/dshean/pygeotools\n",
    "+ `rasterio` -- https://github.com/mapbox/rasterio\n",
    "\n",
    "First, we specify our DEM filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'input_data/AUS_LR.tiff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show how this can be done using rasterio. First we load the required libraries and then define the requested projection (here we used EPSG reference for the region EPSG:28355)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio import crs\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio import drivers\n",
    "\n",
    "# Reproject to EPSG zone\n",
    "dst_crs = {'init': 'EPSG:28355'}\n",
    "\n",
    "# Requested reprojected dataset resolution (metres)\n",
    "utmRes = 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the following cell to make the projection and get the interpolated elevation points at the requested resolution (elev -- a numpy masked array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(filename) as src:\n",
    "    array = src.read(1)\n",
    "    print(array.shape, array.dtype)\n",
    "    \n",
    "    plt.imshow(array, cmap='pink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(filename) as src:\n",
    "\n",
    "    profile = src.profile\n",
    "    print(profile)\n",
    "    if src.nodata is None:\n",
    "        nodata = -100000\n",
    "    else:\n",
    "        nodata = src.nodata\n",
    "\n",
    "    if src.crs is None:\n",
    "        src_crs = src_crs\n",
    "    else:\n",
    "        src_crs = src.crs\n",
    "\n",
    "    # Calculate the ideal dimensions and transformation in the new crs\n",
    "    dst_affine, dst_width, dst_height = calculate_default_transform(\n",
    "        src_crs, dst_crs, src.width, src.height, *src.bounds, resolution=utmRes)\n",
    "\n",
    "    # update the relevant parts of the profile\n",
    "    profile.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': dst_affine,\n",
    "        'width': dst_width,\n",
    "        'height': dst_height,\n",
    "    })\n",
    "\n",
    "    # Reproject and write each band\n",
    "    src_array = src.read()\n",
    "    dst_array = np.empty((int(dst_height), int(dst_width)), dtype='float32')\n",
    "\n",
    "    reproject(\n",
    "            # Source parameters\n",
    "            source=src_array,\n",
    "            src_crs=src_crs,\n",
    "            src_transform=src.transform,\n",
    "            src_nodata=nodata,\n",
    "\n",
    "            # Destination paramaters\n",
    "            destination=dst_array,\n",
    "            dst_transform=dst_affine,\n",
    "            dst_crs=dst_crs,\n",
    "            dst_nodata=nodata,\n",
    "\n",
    "            # Configuration\n",
    "            resampling=Resampling.nearest,\n",
    "            num_threads=2)\n",
    "\n",
    "    elev = np.ma.masked_where(dst_array == nodata, dst_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the metadata associated with the new GeoTIFF file using for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clipped elevation grid\n",
    "\n",
    "We can visualise the new elevation array using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotElevation( data, cmin, cmax, colormap):\n",
    "    '''\n",
    "    data: dataset to plot\n",
    "    zmin,zmax: extent of the colormap\n",
    "    colormap: to use    \n",
    "    '''\n",
    "    \n",
    "    # Figure size is defined here\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(data, interpolation='nearest', cmap=colormap,\n",
    "                     vmin=cmin, vmax=cmax)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    cbar = plt.colorbar(im,cax=cax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_max_elevation =  2000\n",
    "vis_min_elevation = -1000\n",
    "\n",
    "topocmap = 'pink'\n",
    "plotElevation( elev, vis_min_elevation, vis_max_elevation, topocmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = elev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X & Y axes\n",
    "\n",
    "To keep your coordinates system for post-processing and to potentially reproject the outputs from the landscape evolution model in another geospatial system we needs to specify the X and Y axes.\n",
    "We do it like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xMin = dst_affine[2]\n",
    "xMax = dst_affine[2] + abs(dst_affine[0])*dst_width\n",
    "\n",
    "yMin = dst_affine[5] - abs(dst_affine[4])*dst_height\n",
    "yMax = dst_affine[5]\n",
    "\n",
    "print(\"Initial DEM:\\n\")\n",
    "\n",
    "print(\"Lower left coordinates       Xmin: {}, Ymin: {}\".format(xMin,yMin))\n",
    "print(\"Upper right coordinates      Xmax:  {}, Ymax: {}\".format(xMax,yMax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the X and Y coordinates, at this point we can choose to decrease the resolution if needed by using the step parameter (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "spacing = utmRes*step\n",
    "\n",
    "Z = dem[::step,::step]\n",
    "\n",
    "nx = Z.shape[1]\n",
    "ny = Z.shape[0]\n",
    "\n",
    "minX, maxX = xMin, xMin+spacing*nx\n",
    "minY, maxY = yMin, yMin+spacing*ny\n",
    "\n",
    "xcoords = np.arange(minX, maxX, spacing)\n",
    "ycoords = np.arange(minY, maxY, spacing)\n",
    "\n",
    "X, Y = np.meshgrid(xcoords, ycoords)\n",
    "\n",
    "coords = np.vstack([X.ravel(), Y.ravel()])\n",
    "\n",
    "print(\"Clipped DEM:\\n\")\n",
    "\n",
    "print(\"Resolution (m)            res: {}\".format(spacing))\n",
    "print(\"Number of points         nbpt: {}\".format(coords.shape[0]))\n",
    "print(\"Elevation map shape        nx: {}, ny: {}\\n\".format(nx,ny))\n",
    "\n",
    "print(\"Lower left coordinates   Xmin: {}, Ymin: {}\".format(minX,minY))\n",
    "print(\"Upper right coordinates  Xmax: {}, Ymax: {}\".format(maxX,maxY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define contour lines\n",
    "\n",
    "From the projected digital elevation, we will extract contour lines at given depth and use these lines to define the extent of our simulation region and its resolution. \n",
    "\n",
    "First we define the `extractContours` function that returns the list of countour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractContours( X, Y, Z, cmin, cmax, colormap, ctrlist):\n",
    "    '''\n",
    "    coords: coordinate points (X,Y,X)\n",
    "    cmin,cmax: extent of the colormap\n",
    "    colormap: color scale to use\n",
    "    ctrlist: list of contours to extract\n",
    "    '''\n",
    "    # Figure size is defined here\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    ctrs = []\n",
    "    for k in range(len(ctrlist)):\n",
    "        print(k, len(ctrlist), ctrlist[k], type(ctrlist[k]))\n",
    "        ctrs.append(plt.contour(X, Y, \n",
    "                    np.flipud(Z), [ctrlist[k]]))\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(Z, interpolation='nearest', cmap=colormap,\n",
    "                     vmin=cmin, vmax=cmax,extent=[minX, maxX,minY, maxY])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    cbar = plt.colorbar(im,cax=cax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return ctrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we specify a list of contour line depths `ctrList` that needs to be defined in **ascending order** (this is important for what follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_contour = -12.\n",
    "\n",
    "\n",
    "ctrList = [depth_contour,]\n",
    "# Now we extract the contours lines using the previous function\n",
    "if sorted(ctrList) == ctrList:\n",
    "    ctrs = extractContours(X, Y, Z, vis_min_elevation, vis_max_elevation, topocmap, ctrList)\n",
    "else:\n",
    "    print(\"ERROR:\")\n",
    "    print(\"The list of contour positions needs to be specify in ascending order!\")\n",
    "    print(\"Redefine the ctrList variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ctrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the figure above that we have several contour lines for any single depth. We will only use the **longest lines for each depth** to define our simulation domain.\n",
    "\n",
    "To do so we will define two functions:\n",
    "+ `distancePts`: that will be used to get the euclidian distance between 2 points\n",
    "+ `getLongestContoursXY`: that extract the longest lines and resample it based on a characteristic length `lcar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancePts(p1,p2):\n",
    "    '''\n",
    "    Compute the euclidian distance between 2 points (p1, p2)\n",
    "    \n",
    "    '''\n",
    "    return (p1[1]-p2[1])**2+(p1[0]-p2[0])**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLongestContoursXY(ctrs, lcar):\n",
    "    '''\n",
    "    1- Extract from the list of contour points the longest path\n",
    "    2- Using a characteristic length (lcar) resample the path \n",
    "    3- Return the XY coordinates of the longest paths\n",
    "    '''\n",
    "\n",
    "    ctrPoints = []\n",
    "    # Loop through the contour lines \n",
    "    for ct in range(len(ctrs)):\n",
    "        cpath = []\n",
    "        k = 0\n",
    "        maxpts = 0\n",
    "        pathID = 0\n",
    "        \n",
    "        # For each contour extract the longest path\n",
    "        for collection in ctrs[ct].collections:\n",
    "            for path in collection.get_paths():\n",
    "                if len(path)>4:\n",
    "                    cpath.append(np.asarray(path.to_polygons()[0]))\n",
    "                    # Storing longest path\n",
    "                    if cpath[-1].shape[0] > maxpts:\n",
    "                        maxpts =  cpath[-1].shape[0]\n",
    "                        pathID = k\n",
    "                    k += 1\n",
    "\n",
    "        # Find longest path XY coordinates \n",
    "        Cpts = cpath[pathID]\n",
    "        x = Cpts[:,0]\n",
    "        y = Cpts[:,1]\n",
    "        tmp = OrderedDict()\n",
    "        for pt in zip(x,y):\n",
    "            tmp.setdefault(pt[:1], pt)   \n",
    "        ctrPts = np.asarray(list(tmp.values()))\n",
    "        # Resample the path to the requested characteristic length\n",
    "        ki = 0\n",
    "        tmpPts = []\n",
    "        cumdist = 0.\n",
    "        tmpPts.append(ctrPts[0,:])\n",
    "        for k in range(1,ctrPts.shape[0]):\n",
    "            cumdist = distancePts(ctrPts[ki,:2], ctrPts[k,:2])\n",
    "            if(cumdist >= lcar):\n",
    "                tmpPts.append(ctrPts[k,:])\n",
    "                ki = k\n",
    "        ctrPoints.append(np.asarray(tmpPts))\n",
    "\n",
    "    return ctrPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `getLongestContoursXY` function will return the longest line resampled points coordinates for each contour depths defined in `ctrList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrPoints = getLongestContoursXY(ctrs,1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the picked contour lines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotContours( X, Y, Z, cmin, cmax, colormap, ctrPts):\n",
    "    '''\n",
    "    coords: coordinate points (X,Y)\n",
    "    zmin,zmax: extent of the colormap\n",
    "    colormap: to use  \n",
    "    ctrPts: coordinates of contour lines\n",
    "    '''\n",
    "    # Figure size is defined here\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    ctrs = []\n",
    "    for k in range(len(ctrPts)):\n",
    "        plt.scatter(ctrPts[k][:,0], ctrPts[k][:,1], s=0.3, c='k')\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(Z, interpolation='nearest', cmap=colormap,\n",
    "                     vmin=cmin, vmax=cmax,extent=[minX, maxX,minY, maxY])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "    cbar = plt.colorbar(im,cax=cax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotContours(X, Y, Z, vis_min_elevation, vis_max_elevation, topocmap, ctrPoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the meshing\n",
    "\n",
    "We use the [JigsawPy](https://github.com/dengwirda/jigsaw-python) tool to perform triangular meshing, with mesh refinement based on an arbitrary function - in this case, the mesh is refined in areas of high slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a folder to store all the output data\n",
    "dst_path = \"output_data\"\n",
    "\n",
    "# setup jigsaw mesh storage\n",
    "opts = jigsawpy.jigsaw_jig_t()\n",
    "geom = jigsawpy.jigsaw_msh_t()\n",
    "mesh = jigsawpy.jigsaw_msh_t()\n",
    "# refinement function mesh\n",
    "hfun = jigsawpy.jigsaw_msh_t()\n",
    "\n",
    "opts.geom_file = os.path.join(dst_path, \"pslg.msh\")\n",
    "opts.jcfg_file = os.path.join(dst_path, \"pslg.jig\")\n",
    "opts.mesh_file = os.path.join(dst_path, \"mesh.msh\")\n",
    "opts.hfun_file = os.path.join(dst_path, \"spac.msh\")\n",
    "\n",
    "# The output name of the mesh we'll use for gLEC\n",
    "output_vtk = os.path.join(dst_path, \"AUS_LR.vtk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the data\n",
    "\n",
    "We take the contour points found in the previous step, and create a closed polygon out of them.\n",
    "\n",
    "We do this by first adding all the contour points as vertexes, and then we link each vertex with edges. Notice we also link the first and last vertexes with an edge too, so the loop is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Setup contour points as a big polygon\n",
    "geom.mshID = \"euclidean-mesh\"\n",
    "geom.ndims = +2\n",
    "\n",
    "# For each point in the contour, add it as a vertex\n",
    "arr = []\n",
    "for i in range(ctrPoints[0].shape[0]):\n",
    "    arr.append(([ctrPoints[0][i][0], ctrPoints[0][i][1]], 0))\n",
    "    \n",
    "arr = np.array(arr, dtype=geom.VERT2_t)\n",
    "geom.vert2 = arr\n",
    "\n",
    "# Now link each vertex with a line, remembering to link the first\n",
    "# and last points too.\n",
    "lineLoop=[]\n",
    "for i in range(ctrPoints[0].shape[0]):\n",
    "    if i < ctrPoints[0].shape[0]-1:\n",
    "        lineLoop.append(([i, i+1], 0))\n",
    "    else:\n",
    "        lineLoop.append(([i, 0], 0))\n",
    "edges = np.array(lineLoop, dtype=geom.EDGE2_t)\n",
    "geom.edge2 = edges\n",
    "\n",
    "jigsawpy.savemsh(opts.geom_file, geom)\n",
    "#\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh refinement\n",
    "\n",
    "We define the arbitrary function in the `hfun` mesh. This is a euclidean grid, and the value at each point will determine how well refined the final triangular mesh should be in that area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfun.mshID = \"euclidean-grid\"\n",
    "hfun.ndims = +2\n",
    "\n",
    "hfun.xgrid = xcoords\n",
    "hfun.ygrid = ycoords\n",
    "\n",
    "# The approximate min and max size for the final triangular mesh cells\n",
    "hmin = 10000.\n",
    "hmax = 200000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing where to refine\n",
    "\n",
    "Since gLEC is finding the connectivity of different elevations, we need to get as much detail as possible in areas where elevation is changing. Therefore, the gradient of elevation, or the slope, is a good proxy for choosing where to have a higher resolution.\n",
    "\n",
    "Here we define a grid of the gradient of elevation, with some processing steps to smooth it out and clamp the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a copy of the data into a jigsaw compatible format\n",
    "out = np.flipud(Z).astype(dtype=jigsawpy.jigsaw_msh_t.REALS_t, copy=True)\n",
    "sea_mask = out < depth_contour\n",
    "land_mask = np.logical_not(sea_mask)\n",
    "\n",
    "# Take the magnitude of the gradient of the topo, \n",
    "grad = np.linalg.norm(np.gradient(out), axis=0)\n",
    "# Set the gradient to be 0 in areas we don't care about\n",
    "grad[sea_mask] = 0.\n",
    "\n",
    "# Take the squareroot (or something similar) to reduce the variance of the gradient\n",
    "# Varying the power will change how 'focused' the refinement is in areas of high\n",
    "# gradient.\n",
    "scaled = np.power(grad, 0.15)\n",
    "smax = np.max(scaled[land_mask])\n",
    "\n",
    "# While this is not a normal distribution, we can use these stats\n",
    "# to help focus the refinement.\n",
    "land_std  = np.std(scaled[land_mask])\n",
    "land_mean = np.mean(scaled[land_mask])\n",
    "\n",
    "# Use the stats to clamp the hfun, so we get better meshing.\n",
    "scaled[scaled < land_mean - land_std] = land_mean - land_std\n",
    "scaled[scaled > land_mean + land_std] = land_mean + land_std\n",
    "\n",
    "# Flip the sign of the gradient field, so areas with high gradient have small numbers\n",
    "# (corresponding with small mesh size)\n",
    "scaled = smax - scaled\n",
    "\n",
    "# Now scale the gradient to fit between the min and max size for the mesh\n",
    "scaled = ((scaled - np.min(scaled)) / (np.max(scaled) - np.min(scaled))) * (hmax - hmin) + hmin\n",
    "\n",
    "# Now transfer the finalised function into the hfun mesh\n",
    "hfun.value = scaled\n",
    "\n",
    "jigsawpy.savemsh(opts.hfun_file, hfun)\n",
    "\n",
    "# Apply the refinement\n",
    "jigsawpy.cmd.marche(opts, hfun)\n",
    "\n",
    "#\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refinement output\n",
    "\n",
    "We can visualise the hfun mesh, and see which areas will have higher resolution (smaller values), and which areas will have lower resolution (higher values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.flipud(hfun.value), vmin=hmin, vmax=hmax, cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputting the mesh\n",
    "\n",
    "Now we can tell jigsaw to generate the final mesh, populate its vertexes with elevation data, and write it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.hfun_scal = \"absolute\"\n",
    "opts.hfun_hmin = hmin\n",
    "opts.hfun_hmax = hmax\n",
    "\n",
    "opts.mesh_dims = +2                 # 2-dim. simplexes\n",
    "\n",
    "# If you need the contour line to be well preserved\n",
    "# enable geom_feat, and use geom_eta1 to control how fine\n",
    "# it should be\n",
    "#opts.geom_feat = True               # do sharp feature\n",
    "#opts.geom_eta1 = 45.\n",
    "opts.mesh_top1 = True               # preserve 1-topo.\n",
    "\n",
    "opts.mesh_eps1 = 1.0                # relax edge error\n",
    "\n",
    "opts.optm_qlim = +9.5E-01           # tighter opt. tol\n",
    "opts.optm_iter = +32\n",
    "opts.optm_qtol = +1.0E-05\n",
    "\n",
    "jigsawpy.cmd.jigsaw(opts, mesh)\n",
    "\n",
    "# Populate the Jigsaw mesh vertexes with the topographic data\n",
    "zfun = RectBivariateSpline(xcoords,ycoords,np.flipud(Z).T)\n",
    "mesh.value = zfun(mesh.point['coord'][:,0], mesh.point['coord'][:,1], grid=False)\n",
    "\n",
    "\n",
    "# Save the mesh. We can now use this for gLEC, or view it in Paraview\n",
    "outmesh = meshio.Mesh(mesh.point['coord'], {'triangle': mesh.tria3['index']}, {'Z':mesh.value})\n",
    "meshio.write(output_vtk, outmesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick visualation\n",
    "\n",
    "We can have a simple preview of the mesh by using Matplotlib, however, the outputs are best viewed in a tool like Paraview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.tri as mtri\n",
    "\n",
    "triang = mtri.Triangulation(mesh.point['coord'][:,0], mesh.point['coord'][:,1], mesh.tria3['index'])\n",
    "fig, ax = plt.subplots()\n",
    "ax.triplot(triang)\n",
    "ax.set_aspect('equal')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
